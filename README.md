# ğŸ§  Machine Learning Pipeline Notebook

This Jupyter Notebook demonstrates a complete pipeline for building and optimizing machine learning models. It walks through essential steps like data preprocessing, feature engineering, model training, and evaluation using popular Python libraries.

## ğŸ“ Notebook Structure

1. **Importing Necessary Packages**
2. **Data Loading**
3. **Data Exploration**
4. **Data Preprocessing**
5. **Feature Selection & Dimensionality Reduction**
6. **Model Training**
   - Random Forest
   - XGBoost
   - LightGBM
7. **Hyperparameter Tuning**
8. **Model Evaluation & Visualization**

---

## ğŸ—‚ï¸ Project Overview

The notebook guides you through:

- ğŸ“Š **Data Exploration** â€“ Understanding and profiling the dataset
- ğŸ§¹ **Data Cleaning** â€“ Handling missing values and inconsistencies
- ğŸ§¬ **Feature Engineering** â€“ Encoding, scaling, and transforming variables
- ğŸ“‰ **Dimensionality Reduction** â€“ Applying PCA and SelectKBest
- ğŸ¤– **Model Training** â€“ Using Random Forest, XGBoost, and LightGBM
- ğŸ” **Hyperparameter Tuning** â€“ GridSearchCV optimization
- ğŸ“ˆ **Evaluation** â€“ Confusion matrix, classification report, and visual insights

---

## ğŸ“¦ Tech Stack

| Category         | Libraries Used |
|------------------|----------------|
| Data Handling    | `pandas`, `numpy` |
| Visualization    | `matplotlib`, `seaborn` |
| Preprocessing    | `scikit-learn`, `SimpleImputer`, `OneHotEncoder`, `StandardScaler` |
| Feature Selection| `SelectKBest`, `PCA` |
| ML Algorithms    | `RandomForestClassifier`, `XGBClassifier`, `LGBMClassifier` |
| Tuning & Workflow| `Pipeline`, `ColumnTransformer`, `GridSearchCV` |
| Dataset Access   | `kagglehub` |

---

## ğŸ“¦ Dependencies

Make sure to install the following Python libraries:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost lightgbm kagglehub
